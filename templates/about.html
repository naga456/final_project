<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Damajs</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css">
    <!--Solution copied from web-->
    <link rel= "stylesheet" type= "text/css" href= "{{ url_for('static',filename='styles/style.css') }}">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">

</head>

<body class="bg-primary">
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <a class="navbar-brand" href="/">Damajs</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
      
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav mr-auto">
            <li class="nav-item active">
              <a class="nav-link" href="/">Home <span class="sr-only">(current)</span></a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/about">About</a>
            </li>
            <li class="nav-item">
              <a href="/technology" class="nav-link" >Technology</a>
            </li>
            <li class="nav-item">
                <a href="http://localhost:8888/notebooks/data_cleanup.ipynb" class="nav-link" >Jupyter Notebook</a>
            </li>
          </ul>
        </div>
    </nav>

  <p><h1>About my project:</h1>
    <br>
    I really wanted to challenge myself and take on integration problems head on.
    <br>
    I thought the job searching process was very frustrating and I wanted to see if there was a better way of doing it
    using what we learned about data analytics and machine learning.  
    <br> This application takes a resume or description about your work experience and compares it using concepts similar to sentiment analysis to classify job categories.  
    <br>Job descriptions were pulled for 5 different job categories and used to train a naive bayes model.
    <br>
    <hr>
    <h2>The visualization:</h2>  Takes in the text input and figure outs the important words.  Once we classify and predict your job category,
    we compare your key words to job descriptions within your job category.  
    <br>The size of the word is used to find its strength in relation
    to using the word to predict using TFID weight.
    <br>
  </p>
    
  <p><h1>Design:</h1></p>
    <img src="/static/design.jpg">

  <ol><h1>Usage:</h1></ol>
  <ol>
    <li> load the data into pandas to clean it up.</li>
    <li> save the data to csv.</li>
    <li> train the model against the clean data.</li>
    <li> save the model to be used later.</li>
    <li> build the database in PGadmin.</li>
    <li> Load the clean data csv.</li>
    <li> Load the webpage and the user can copy their resume into the text area.</li>
    <li> The HTML passes the input to Flask.</li>
    <li> Clean the input using the same method as the model.</li>
    <li> Use the prediction to query the database for a list of job descriptions matching the prediction.</li>
    <li> Apply TFIDF (term frequency-inverse document frequency) to the list to find the word weights. </li>
    <li> Create a dictionary of words and weights.</li>
    <li> Flask sends the prediciton and dictionary to the HTML page.</li>
    <li> HTML page displays the prediciton.</li>
    <li> HTML page sends the dictionary to JavaScript to make the visualization.</li>
    <li> The visualization is displayed on the HTML.</li>
  </ol>

  <ol><h1>Interesting Findings:</h1></ol>
  <ol>
    <li>  Without stopwords, the model had a score of 65%.
        <br>With stopwords cleaning the model had a score of 67%</li>
    <li>  I'm not 100% sure the word weights are conveying the weights the model is using. </li>
    <li>  Text analysis and classification didn't require a large dataset.</li>
  </ol>

  <ul style="list-style-type:circle;"> <h1>Improvements:</h1> </ul>
  <li>Add visualization that plots job descriptions in space, add the input in that space and grab the top 10 job descriptions by Euclidian distance of vectorized feature space.</li>
  <li>Add API and webscraping for LinkedIn and Indeed to grab real time job descriptions. </li>
  <li>Apply additional model tuning such as stemming, ngrams, add additional categories. </li>
  <li>Add additional datasets</li>
  <li>Error handling.</li>

</body>

</html>